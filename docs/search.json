[{"path":"/authors.html","id":null,"dir":"","previous_headings":"","what":"Authors","title":"Authors and Citation","text":"First Last. Author, maintainer.","code":""},{"path":"/authors.html","id":"citation","dir":"","previous_headings":"","what":"Citation","title":"Authors and Citation","text":"Last F (2023). stove: Package (One Line, Title Case). R package version 0.0.0.9000.","code":"@Manual{,   title = {stove: What the Package Does (One Line, Title Case)},   author = {First Last},   year = {2023},   note = {R package version 0.0.0.9000}, }"},{"path":"/index.html","id":"yellow_heart-stove-","dir":"","previous_headings":"","what":"What the Package Does (One Line, Title Case)","title":"What the Package Does (One Line, Title Case)","text":"Description stove","code":""},{"path":"/index.html","id":"wrench-install","dir":"","previous_headings":"","what":"🔧 Install","title":"What the Package Does (One Line, Title Case)","text":"","code":"# install.packages(\"devtools\") devtools::install_github(\"statgarten/stove\")"},{"path":"/index.html","id":"example-code","dir":"","previous_headings":"","what":"Example Code","title":"What the Package Does (One Line, Title Case)","text":"documents contain example code ML workflows using stove.","code":""},{"path":"/index.html","id":"sample-data-import","dir":"","previous_headings":"Example Code","what":"Sample Data Import","title":"What the Package Does (One Line, Title Case)","text":"Example code Sample Data Import","code":""},{"path":"/index.html","id":"data-split-and-define-preprocessing","dir":"","previous_headings":"Example Code","what":"Data split and Define preprocessing","title":"What the Package Does (One Line, Title Case)","text":"Example code Data split Define preprocessing","code":""},{"path":"/index.html","id":"modeling","dir":"","previous_headings":"Example Code","what":"Modeling","title":"What the Package Does (One Line, Title Case)","text":"Example code Modeling","code":""},{"path":"/index.html","id":"clipboard-dependency","dir":"","previous_headings":"","what":"📋 Dependency","title":"What the Package Does (One Line, Title Case)","text":"assertthat - 0.2.1base64enc - 0.1-3 … sessioninfo::package_info()","code":""},{"path":"/index.html","id":"blush-authors","dir":"","previous_headings":"","what":"😊 Authors","title":"What the Package Does (One Line, Title Case)","text":"Yeonchan Seong @ycseong07","code":""},{"path":"/index.html","id":"memo-license","dir":"","previous_headings":"","what":"📝 License","title":"What the Package Does (One Line, Title Case)","text":"Copyright ©️ 2022 Yeonchan Seong project MIT licensed","code":""},{"path":"/reference/bayesOptCV.html","id":null,"dir":"Reference","previous_headings":"","what":"Bayesian optimization with cross validation — bayesOptCV","title":"Bayesian optimization with cross validation — bayesOptCV","text":"Bayesian optimization cross validation","code":""},{"path":"/reference/bayesOptCV.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Bayesian optimization with cross validation — bayesOptCV","text":"","code":"bayesOptCV(   rec = NULL,   model = NULL,   v = NULL,   trainingData = NULL,   gridNum = NULL,   iter = NULL,   seed = NULL )"},{"path":"/reference/bayesOptCV.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Bayesian optimization with cross validation — bayesOptCV","text":"rec 데이터, 전처리 정보를 포함한 recipe object model hyperparameters, ngine, mode 정보가 포함된 model object v v-fold cross validation을 진행 (default: 5, 각 fold 별로 30개 이상의 observations가 있어야 유효한 모델링 결과를 얻을 수 있습니다.) trainingData 훈련데이터 셋 iter grid search를 수행할 때 각 hyperparameter의 값을 담은 object seed seed값 설정 initial 몇 개의 grid로","code":""},{"path":"/reference/bayesOptCV.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Bayesian optimization with cross validation — bayesOptCV","text":"교차검증 수행 과정에서, Bayesian optimization을 통해 모델의 하이퍼파라미터를 최적화합니다.","code":""},{"path":"/reference/clusteringVis.html","id":null,"dir":"Reference","previous_headings":"","what":"clusteringVis — clusteringVis","title":"clusteringVis — clusteringVis","text":"clusteringVis","code":""},{"path":"/reference/clusteringVis.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"clusteringVis — clusteringVis","text":"","code":"clusteringVis(   data = NULL,   model = NULL,   maxK = \"15\",   nBoot = \"100\",   selectOptimal = \"silhouette\",   seedNum = \"6471\" )"},{"path":"/reference/clusteringVis.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"clusteringVis — clusteringVis","text":"data data model model maxK maxK nStart nStart","code":""},{"path":"/reference/clusteringVis.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"clusteringVis — clusteringVis","text":"Deprecated","code":""},{"path":"/reference/decisionTree.html","id":null,"dir":"Reference","previous_headings":"","what":"Decision Tree — decisionTree","title":"Decision Tree — decisionTree","text":"Decision Tree","code":""},{"path":"/reference/decisionTree.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Decision Tree — decisionTree","text":"","code":"decisionTree(   algo = \"Decision Tree\",   engine = \"rpart\",   mode = \"classification\",   trainingData = NULL,   splitedData = NULL,   formula = NULL,   rec = NULL,   v = 5,   gridNum = 5,   iter = 10,   metric = NULL,   seed = 1234 )"},{"path":"/reference/decisionTree.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Decision Tree — decisionTree","text":"algo 사용자가 임의로 지정할 알고리즘명 (default: \"Decision Tree\") engine 모델을 생성할 때 사용할 패키지 (\"rpart\" (default), \"C50\", \"partykit\") mode 분석 유형 (\"classification\" (default), \"regression\") trainingData 훈련데이터 셋 splitedData train-test 데이터 분할 정보를 포함하고 있는 전체 데이터 셋 formula 모델링을 위한 수식 rec 데이터, 전처리 정보를 포함한 recipe object v v-fold cross validation을 진행 (default: 5, 각 fold 별로 30개 이상의 observations가 있어야 유효한 모델링 결과를 얻을 수 있습니다.) metric 모델의 성능을 평가할 기준지표 (classification: \"roc_auc\" (default), \"accuracy\" / regression: \"rmse\" (default), \"rsq\") ... hyperparameters의 범위에 대한 Min, Max, Levels 값에 해당하는 파라미터를 지정합니다.","code":""},{"path":"/reference/decisionTree.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Decision Tree — decisionTree","text":"의사결정나무 알고리즘 함수. 의사 결정 규칙 (Decision rule)을 나무 형태로 분류해 나가는 분석 기법을 말합니다. hyperparameters: tree_depth: 최종 예측값에 다다르기까지 몇 번 트리를 분할할지 설정합니다. min_n: 트리를 분할하기 위해 필요한 관측값의 최소 개수를 설정합니다. cost_complexity: 트리 분할을 위해 필요한 비용을 설정합니다. 0일 경우, 가능한 모든 분할이 수행됩니다.","code":""},{"path":"/reference/evalMetricsR.html","id":null,"dir":"Reference","previous_headings":"","what":"Evaluation metrics for Regression — evalMetricsR","title":"Evaluation metrics for Regression — evalMetricsR","text":"Evaluation metrics Regression","code":""},{"path":"/reference/evalMetricsR.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Evaluation metrics for Regression — evalMetricsR","text":"","code":"evalMetricsR(modelsList, targetVar)"},{"path":"/reference/evalMetricsR.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Evaluation metrics for Regression — evalMetricsR","text":"modelsList ML 모델 리스트 targetVar 타겟 변수","code":""},{"path":"/reference/evalMetricsR.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Evaluation metrics for Regression — evalMetricsR","text":"ML 모델 리스트로부터 Regression 모델들에 대한 Evaluation metrics를 생성합니다.","code":""},{"path":"/reference/fitBestModel.html","id":null,"dir":"Reference","previous_headings":"","what":"fitting in best model — fitBestModel","title":"fitting in best model — fitBestModel","text":"fitting best model","code":""},{"path":"/reference/fitBestModel.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"fitting in best model — fitBestModel","text":"","code":"fitBestModel(   optResult,   metric,   model,   formula,   trainingData,   splitedData,   algo )"},{"path":"/reference/fitBestModel.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"fitting in best model — fitBestModel","text":"optResult gridSearchCV의 결과값 metric 모델의 성능을 평가할 기준지표 (classification: \"roc_auc\" (default), \"accuracy\" / regression: \"rmse\" (default), \"rsq\") model hyperparameters, ngine, mode 정보가 포함된 model object formula 모델링을 위한 수식 trainingData 훈련데이터 셋 splitedData train-test 데이터 분할 정보를 포함하고 있는 전체 데이터 셋 algo 사용자가 임의로 지정할 알고리즘명 (default: \"linear Regression\")","code":""},{"path":"/reference/fitBestModel.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"fitting in best model — fitBestModel","text":"gridSearchCV 함수 리턴값을 받아 가장 성능이 좋은 모델을 fitting합니다.","code":""},{"path":"/reference/gridSearchCV.html","id":null,"dir":"Reference","previous_headings":"","what":"Grid search with cross validation — gridSearchCV","title":"Grid search with cross validation — gridSearchCV","text":"Grid search cross validation","code":""},{"path":"/reference/gridSearchCV.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Grid search with cross validation — gridSearchCV","text":"","code":"gridSearchCV(   rec = NULL,   model = NULL,   v = NULL,   trainingData = NULL,   parameterGrid = NULL,   seed = NULL )"},{"path":"/reference/gridSearchCV.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Grid search with cross validation — gridSearchCV","text":"rec 데이터, 전처리 정보를 포함한 recipe object model hyperparameters, ngine, mode 정보가 포함된 model object v v-fold cross validation을 진행 (default: 5, 각 fold 별로 30개 이상의 observations가 있어야 유효한 모델링 결과를 얻을 수 있습니다.) trainingData 훈련데이터 셋 seed seed값 설정 parameter_grid grid search를 수행할 때 각 hyperparameter의 값을 담은 object","code":""},{"path":"/reference/gridSearchCV.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Grid search with cross validation — gridSearchCV","text":"하이퍼파라미터를 탐색하는 Grid Search와 데이터 셋을 나누어 평가하는 cross validation을 함께 수행합니다.","code":""},{"path":"/reference/kMeansClustering.html","id":null,"dir":"Reference","previous_headings":"","what":"K means clustering — kMeansClustering","title":"K means clustering — kMeansClustering","text":"K means clustering","code":""},{"path":"/reference/kMeansClustering.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"K means clustering — kMeansClustering","text":"","code":"kMeansClustering(   data,   maxK = 15,   nStart = 25,   iterMax = 10,   nBoot = 100,   algorithm = \"Hartigan-Wong\",   selectOptimal = \"silhouette\",   seedNum = 6471 )"},{"path":"/reference/kMeansClustering.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"K means clustering — kMeansClustering","text":"data 전처리가 완료된 데이터 maxK 클러스터링 수행 시 군집을 2, 3, ..., maxK개로 분할 (default: 15) iterMax 반복계산을 수행할 최대 횟수 (default: 10) nBoot gap statictic을 사용해 클러스터링을 수행할 때 Monte Carlo (bootstrap) 샘플의 개수 (selectOptimal == \"gap_stat\" 일 경우에만 지정, default: 100) algorithm K means를 수행할 알고리즘 선택 (\"Hartigan-Wong\" (default), \"Lloyd\", \"Forgy\", \"MacQueen\") selectOptimal 최적의 K값을 선정할 때 사용할 method 선택 (\"silhouette\" (default), \"gap_stat\") seedNum seed값 설정 nstart 랜덤 샘플에 대해 초기 클러스터링을 nstart번 시행 (default: 25)","code":""},{"path":"/reference/kMeansClustering.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"K means clustering — kMeansClustering","text":"K means clustering selectOptimal: silhouette, gap_stat hyperparameters: maxK, nstart","code":""},{"path":"/reference/KNN.html","id":null,"dir":"Reference","previous_headings":"","what":"K-Nearest Neighbors — KNN","title":"K-Nearest Neighbors — KNN","text":"K-Nearest Neighbors","code":""},{"path":"/reference/KNN.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"K-Nearest Neighbors — KNN","text":"","code":"KNN(   algo = \"KNN\",   engine = \"kknn\",   mode = \"classification\",   trainingData = NULL,   splitedData = NULL,   formula = NULL,   rec = NULL,   v = 5,   gridNum = 5,   iter = 10,   metric = NULL,   seed = 1234 )"},{"path":"/reference/KNN.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"K-Nearest Neighbors — KNN","text":"algo 사용자가 임의로 지정할 알고리즘명 (default: \"KNN\") engine 모델을 생성할 때 사용할 패키지 (\"kknn\" (default)) mode 분석 유형 (\"classification\" (default), \"regression\") trainingData 훈련데이터 셋 splitedData train-test 데이터 분할 정보를 포함하고 있는 전체 데이터 셋 formula 모델링을 위한 수식 rec 데이터, 전처리 정보를 포함한 recipe object v v-fold cross validation을 진행 (default: 5, 각 fold 별로 30개 이상의 observations가 있어야 유효한 모델링 결과를 얻을 수 있습니다.) metric 모델의 성능을 평가할 기준지표 (classification: \"roc_auc\" (default), \"accuracy\" / regression: \"rmse\" (default), \"rsq\") ... hyperparameters의 범위에 대한 Min, Max, Levels 값에 해당하는 파라미터를 지정합니다.","code":""},{"path":"/reference/KNN.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"K-Nearest Neighbors — KNN","text":"KNN 알고리즘 함수. 데이터로부터 거리가 가까운 K개의 다른 데이터의 레이블을 참조하여 분류하는 알고리즘 hyperparameters: neighbors","code":""},{"path":"/reference/lightGbm.html","id":null,"dir":"Reference","previous_headings":"","what":"Light GBM — lightGbm","title":"Light GBM — lightGbm","text":"Light GBM","code":""},{"path":"/reference/lightGbm.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Light GBM — lightGbm","text":"","code":"lightGbm(   algo = \"lightGBM\",   engine = \"lightgbm\",   mode = \"classification\",   trainingData = NULL,   splitedData = NULL,   formula = NULL,   rec = NULL,   v = 5,   gridNum = 5,   iter = 15,   metric = NULL,   seed = 1234 )"},{"path":"/reference/lightGbm.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Light GBM — lightGbm","text":"algo 사용자가 임의로 지정할 알고리즘명 (default: \"lightGBM\") engine 모델을 생성할 때 사용할 패키지 (\"lightgbm\" (default)) mode 분석 유형 (\"classification\" (default), \"regression\") trainingData 훈련데이터 셋 splitedData train-test 데이터 분할 정보를 포함하고 있는 전체 데이터 셋 formula 모델링을 위한 수식 rec 데이터, 전처리 정보를 포함한 recipe object v v-fold cross validation을 진행 (default: 5, 각 fold 별로 30개 이상의 observations가 있어야 유효한 모델링 결과를 얻을 수 있습니다.) metric 모델의 성능을 평가할 기준지표 (classification: \"roc_auc\" (default), \"accuracy\" / regression: \"rmse\" (default), \"rsq\") ... hyperparameters의 범위에 대한 Min, Max, Levels 값에 해당하는 파라미터를 지정합니다.","code":""},{"path":"/reference/lightGbm.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Light GBM — lightGbm","text":"Light GBM","code":""},{"path":"/reference/linearRegression.html","id":null,"dir":"Reference","previous_headings":"","what":"Linear Regression — linearRegression","title":"Linear Regression — linearRegression","text":"Linear Regression","code":""},{"path":"/reference/linearRegression.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Linear Regression — linearRegression","text":"","code":"linearRegression(   algo = \"Linear Regression\",   engine = \"glmnet\",   mode = \"regression\",   trainingData = NULL,   splitedData = NULL,   formula = NULL,   rec = NULL,   v = 5,   gridNum = 5,   iter = 10,   metric = \"rmse\",   seed = 1234 )"},{"path":"/reference/linearRegression.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Linear Regression — linearRegression","text":"algo 사용자가 임의로 지정할 알고리즘명 (default: \"Linear Regression\") engine 모델을 생성할 때 사용할 패키지 (\"glmnet\" (default), \"lm\", \"glm\", \"stan\") mode 분석 유형 (\"regression\" (default)) trainingData 훈련데이터 셋 splitedData train-test 데이터 분할 정보를 포함하고 있는 전체 데이터 셋 formula 모델링을 위한 수식 rec 데이터, 전처리 정보를 포함한 recipe object v v-fold cross validation을 진행 (default: 5, 각 fold 별로 30개 이상의 observations가 있어야 유효한 모델링 결과를 얻을 수 있습니다.) metric 모델의 성능을 평가할 기준지표 (classification: \"roc_auc\" (default), \"accuracy\" / regression: \"rmse\" (default), \"rsq\") ... hyperparameters의 범위에 대한 Min, Max, Levels 값에 해당하는 파라미터를 지정합니다.","code":""},{"path":"/reference/linearRegression.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Linear Regression — linearRegression","text":"선형 회귀 알고리즘 함수. 선형회귀는 다음과 같은 가정을 합니다. 1) target - features 간의 선형성, 2) features 간 작은 다중공선성, 3) 등분산성 가정, 4) 오차항의 정규분포, 5) 오차항 간 적은 상관성. 만약 데이터가 이 가정을 충족하지 않는 경우 성능이 저하될 수 있습니다. hyperparameters: penalty, mixture","code":""},{"path":"/reference/logisticRegression.html","id":null,"dir":"Reference","previous_headings":"","what":"logistic Regression — logisticRegression","title":"logistic Regression — logisticRegression","text":"로지스틱 회귀 알고리즘 함수. 예측 변수들이 정규분포를 따르지 않아도 사용할 수 있습니다. 그러나 이 알고리즘은 결과 변수가 선형적으로 구분되며, 예측 변수들의 값이 결과 변수와 선형 관계를 갖는다고 가정합니다. 만약 데이터가 이 가정을 충족하지 않는 경우 성능이 저하될 수 있습니다.","code":""},{"path":"/reference/logisticRegression.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"logistic Regression — logisticRegression","text":"","code":"logisticRegression(   algo = \"logistic Regression\",   engine = \"glmnet\",   mode = \"classification\",   trainingData = NULL,   splitedData = NULL,   formula = NULL,   rec = NULL,   v = 5,   gridNum = 5,   iter = 10,   metric = \"roc_auc\",   seed = 1234 )"},{"path":"/reference/logisticRegression.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"logistic Regression — logisticRegression","text":"algo 사용자가 임의로 지정할 알고리즘명 (default: \"logistic Regression\") engine 모델을 생성할 때 사용할 패키지 (\"glmnet\" (default)) mode 분석 유형 (\"classification\" (default)) trainingData 훈련데이터 셋 splitedData train-test 데이터 분할 정보를 포함하고 있는 전체 데이터 셋 formula 모델링을 위한 수식 rec 데이터, 전처리 정보를 포함한 recipe object v v-fold cross validation을 진행 (default: 5, 각 fold 별로 30개 이상의 observations가 있어야 유효한 모델링 결과를 얻을 수 있습니다.) metric 모델의 성능을 평가할 기준지표 (classification: \"roc_auc\" (default), \"accuracy\" / regression: \"rmse\" (default), \"rsq\") ... hyperparameters의 범위에 대한 Min, Max, Levels 값에 해당하는 파라미터를 지정합니다.","code":""},{"path":"/reference/logisticRegression.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"logistic Regression — logisticRegression","text":"로지스틱 회귀 알고리즘 함수. 예측 변수들이 정규분포를 따르지 않아도 사용할 수 있습니다. 그러나 이 알고리즘은 결과 변수가 선형적으로 구분되며, 예측 변수들의 값이 결과 변수와 선형 관계를 갖는다고 가정합니다. 만약 데이터가 이 가정을 충족하지 않는 경우 성능이 저하될 수 있습니다. 필요 hyperparameters: penalty, mixture","code":""},{"path":"/reference/MLP.html","id":null,"dir":"Reference","previous_headings":"","what":"neural network — MLP","title":"neural network — MLP","text":"neural network","code":""},{"path":"/reference/MLP.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"neural network — MLP","text":"","code":"MLP(   algo = \"MLP\",   engine = \"nnet\",   mode = \"classification\",   trainingData = NULL,   splitedData = NULL,   formula = NULL,   rec = NULL,   v = 5,   gridNum = 5,   iter = 10,   metric = NULL,   seed = 1234 )"},{"path":"/reference/MLP.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"neural network — MLP","text":"algo 사용자가 임의로 지정할 알고리즘명 (default: \"MLP\") engine 모델을 생성할 때 사용할 패키지 (\"nnet\" (default)) mode 분석 유형 (\"classification\" (default), \"regression\") trainingData 훈련데이터 셋 splitedData train-test 데이터 분할 정보를 포함하고 있는 전체 데이터 셋 formula 모델링을 위한 수식 rec 데이터, 전처리 정보를 포함한 recipe object v v-fold cross validation을 진행 (default: 5, 각 fold 별로 30개 이상의 observations가 있어야 유효한 모델링 결과를 얻을 수 있습니다.) metric 모델의 성능을 평가할 기준지표 (classification: \"roc_auc\" (default), \"accuracy\" / regression: \"rmse\" (default), \"rsq\") ... hyperparameters의 범위에 대한 Min, Max, Levels 값에 해당하는 파라미터를 지정합니다.","code":""},{"path":"/reference/MLP.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"neural network — MLP","text":"neural network 알고리즘 함수. neural network 모델은 생물학적인 뉴런을 수학적으로 모델링한 것. 여러개의 뉴런으로부터 입력값을 받아서 세포체에 저장하다가 자신의 용량을 넘어서면 외부로 출력값을 내보내는 것처럼, 인공신경망 뉴런은 여러 입력값을 받아서 일정 수준이 넘어서면 활성화되어 출력값을 내보낸다. hyperparameters: hidden_units, penalty, dropout, epochs, activation, learn_rate","code":""},{"path":"/reference/naiveBayes.html","id":null,"dir":"Reference","previous_headings":"","what":"Naive Bayes — naiveBayes","title":"Naive Bayes — naiveBayes","text":"Naive Bayes","code":""},{"path":"/reference/naiveBayes.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Naive Bayes — naiveBayes","text":"","code":"naiveBayes(   algo = \"Naive Bayes\",   engine = \"klaR\",   mode = \"classification\",   trainingData = NULL,   splitedData = NULL,   formula = NULL,   rec = NULL,   v = 5,   gridNum = 5,   iter = 10,   metric = NULL,   seed = 1234 )"},{"path":"/reference/naiveBayes.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Naive Bayes — naiveBayes","text":"algo 사용자가 임의로 지정할 알고리즘명 (default: \"Naive Bayes\") engine 모델을 생성할 때 사용할 패키지 (\"klaR\" (default), naivebayes) mode 분석 유형 (\"classification\" (default)) trainingData 훈련데이터 셋 splitedData train-test 데이터 분할 정보를 포함하고 있는 전체 데이터 셋 formula 모델링을 위한 수식 rec 데이터, 전처리 정보를 포함한 recipe object v v-fold cross validation을 진행 (default: 5, 각 fold 별로 30개 이상의 observations가 있어야 유효한 모델링 결과를 얻을 수 있습니다.) metric 모델의 성능을 평가할 기준지표 (classification: \"roc_auc\" (default), \"accuracy\" / regression: \"rmse\" (default), \"rsq\") ... hyperparameters의 범위에 대한 Min, Max, Levels 값에 해당하는 파라미터를 지정합니다.","code":""},{"path":"/reference/naiveBayes.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Naive Bayes — naiveBayes","text":"Naive Bayes hyperparameters: smoothness, Laplace","code":""},{"path":"/reference/pipe.html","id":null,"dir":"Reference","previous_headings":"","what":"AUC-ROC Curve — %>%","title":"AUC-ROC Curve — %>%","text":"AUC-ROC Curve Confusion matrix Regression plot Evaluation metrics Classification","code":""},{"path":"/reference/pipe.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"AUC-ROC Curve — %>%","text":"","code":"rocCurve(modelsList, targetVar)  confusionMatrix(modelName, modelsList, targetVar)  regressionPlot(modelName, modelsList, targetVar)  evalMetricsC(modelsList, targetVar)"},{"path":"/reference/pipe.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"AUC-ROC Curve — %>%","text":"modelsList ML 모델 리스트 targetVar 타겟 변수 modelName 모델명","code":""},{"path":"/reference/pipe.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"AUC-ROC Curve — %>%","text":"ML 모델 리스트로부터 AUC-ROC Curve를 생성합니다. ML 모델 리스트 내 특정 모델에 대해 Confusion matrix를 생성합니다. ML 모델 리스트 내 특정 모델에 대해 Regression plot를 생성합니다. ML 모델 리스트로부터 Classification 모델들에 대한 Evaluation metrics를 생성합니다.","code":""},{"path":"/reference/prepForCV.html","id":null,"dir":"Reference","previous_headings":"","what":"Preprocessing for cross validation — prepForCV","title":"Preprocessing for cross validation — prepForCV","text":"Preprocessing cross validation","code":""},{"path":"/reference/prepForCV.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Preprocessing for cross validation — prepForCV","text":"","code":"prepForCV(   data = NULL,   formula = NULL,   imputation = FALSE,   normalization = FALSE,   nominalImputationType = \"mode\",   numericImputationType = \"mean\",   normalizationType = \"range\",   seed = \"4814\" )"},{"path":"/reference/prepForCV.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Preprocessing for cross validation — prepForCV","text":"data data formula formula imputation imputation normalization normalization normalizationType normalizationType seed seed imputationType imputationType","code":""},{"path":"/reference/prepForCV.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Preprocessing for cross validation — prepForCV","text":"Deprecated","code":""},{"path":"/reference/randomForest.html","id":null,"dir":"Reference","previous_headings":"","what":"Random Forest — randomForest","title":"Random Forest — randomForest","text":"Random Forest","code":""},{"path":"/reference/randomForest.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Random Forest — randomForest","text":"","code":"randomForest(   algo = \"Random Forest\",   engine = \"ranger\",   mode = \"classification\",   trainingData = NULL,   splitedData = NULL,   formula = NULL,   rec = NULL,   v = 5,   gridNum = 5,   iter = 10,   metric = NULL,   seed = 1234 )"},{"path":"/reference/randomForest.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Random Forest — randomForest","text":"algo 사용자가 임의로 지정할 알고리즘명 (default: \"Random Forest\") engine 모델을 생성할 때 사용할 패키지 (\"rpart\" (default), \"randomForest\", \"partykit\") mode 분석 유형 (\"classification\" (default), \"regression\") trainingData 훈련데이터 셋 splitedData train-test 데이터 분할 정보를 포함하고 있는 전체 데이터 셋 formula 모델링을 위한 수식 rec 데이터, 전처리 정보를 포함한 recipe object v v-fold cross validation을 진행 (default: 5, 각 fold 별로 30개 이상의 observations가 있어야 유효한 모델링 결과를 얻을 수 있습니다.) metric 모델의 성능을 평가할 기준지표 (classification: \"roc_auc\" (default), \"accuracy\" / regression: \"rmse\" (default), \"rsq\") ... hyperparameters의 범위에 대한 Min, Max, Levels 값에 해당하는 파라미터를 지정합니다.","code":""},{"path":"/reference/randomForest.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Random Forest — randomForest","text":"랜덤 포레스트 알고리즘 함수. 여러개의 Decision Tree를 형성. 새로운 데이터 포인트를 각 트리에 동시에 통과 시켜 각 트리가 분류한 결과에서 투표를 실시하여 가장 많이 득표한 결과를 최종 분류 결과로 선택 hyperparameters: trees: 결정트리의 개수를 지정합니다. min_n: 트리를 분할하기 위해 필요한 관측값의 최소 개수를 설정합니다. mtry: 트리를 분할하기 위해 필요한 feature의 수를 설정합니다.","code":""},{"path":"/reference/SVMLinear.html","id":null,"dir":"Reference","previous_headings":"","what":"SVMLinear — SVMLinear","title":"SVMLinear — SVMLinear","text":"SVMLinear","code":""},{"path":"/reference/SVMLinear.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"SVMLinear — SVMLinear","text":"","code":"SVMLinear(   algo = \"SVM\",   engine = \"kernlab\",   mode = \"classification\",   trainingData = NULL,   splitedData = NULL,   formula = NULL,   rec = NULL,   v = 5,   gridNum = 5,   iter = 15,   metric = NULL,   seed = 1234 )"},{"path":"/reference/SVMLinear.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"SVMLinear — SVMLinear","text":"SVMLinear","code":""},{"path":"/reference/SVMPoly.html","id":null,"dir":"Reference","previous_headings":"","what":"SVMPoly — SVMPoly","title":"SVMPoly — SVMPoly","text":"SVMPoly","code":""},{"path":"/reference/SVMPoly.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"SVMPoly — SVMPoly","text":"","code":"SVMPoly(   algo = \"SVM\",   engine = \"kernlab\",   mode = \"classification\",   trainingData = NULL,   splitedData = NULL,   formula = NULL,   rec = NULL,   v = 5,   gridNum = 5,   iter = 15,   metric = NULL,   seed = 1234 )"},{"path":"/reference/SVMPoly.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"SVMPoly — SVMPoly","text":"SVMPoly","code":""},{"path":"/reference/SVMRbf.html","id":null,"dir":"Reference","previous_headings":"","what":"SVMRbf — SVMRbf","title":"SVMRbf — SVMRbf","text":"SVMRbf","code":""},{"path":"/reference/SVMRbf.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"SVMRbf — SVMRbf","text":"","code":"SVMRbf(   algo = \"SVM\",   engine = \"kernlab\",   mode = \"classification\",   trainingData = NULL,   splitedData = NULL,   formula = NULL,   rec = NULL,   v = 5,   gridNum = 5,   iter = 15,   metric = NULL,   seed = 1234 )"},{"path":"/reference/SVMRbf.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"SVMRbf — SVMRbf","text":"SVMRbf","code":""},{"path":"/reference/trainTestSplit.html","id":null,"dir":"Reference","previous_headings":"","what":"Train-Test Split — trainTestSplit","title":"Train-Test Split — trainTestSplit","text":"Train-Test Split","code":""},{"path":"/reference/trainTestSplit.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Train-Test Split — trainTestSplit","text":"","code":"trainTestSplit(data = NULL, target = NULL, prop, seed = \"4814\")"},{"path":"/reference/trainTestSplit.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Train-Test Split — trainTestSplit","text":"data 전처리가 완료된 전체 data target 타겟 변수 prop 전체 데이터 중 훈련 데이터로 사용할 비율 seed seed값 설정","code":""},{"path":"/reference/trainTestSplit.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Train-Test Split — trainTestSplit","text":"Data를 Train set과 Test set으로 분리합니다.","code":""},{"path":"/reference/xgBoost.html","id":null,"dir":"Reference","previous_headings":"","what":"XGBoost — xgBoost","title":"XGBoost — xgBoost","text":"XGBoost","code":""},{"path":"/reference/xgBoost.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"XGBoost — xgBoost","text":"","code":"xgBoost(   algo = \"XGBoost\",   engine = \"xgboost\",   mode = \"classification\",   trainingData = NULL,   splitedData = NULL,   formula = NULL,   rec = NULL,   v = 5,   gridNum = 5,   iter = 10,   metric = NULL,   seed = 1234 )"},{"path":"/reference/xgBoost.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"XGBoost — xgBoost","text":"algo 사용자가 임의로 지정할 알고리즘명 (default: \"XGBoost\") engine 모델을 생성할 때 사용할 패키지 (\"xgboost\" (default)) mode 분석 유형 (\"classification\" (default), \"regression\") trainingData 훈련데이터 셋 splitedData train-test 데이터 분할 정보를 포함하고 있는 전체 데이터 셋 formula 모델링을 위한 수식 rec 데이터, 전처리 정보를 포함한 recipe object v v-fold cross validation을 진행 (default: 5, 각 fold 별로 30개 이상의 observations가 있어야 유효한 모델링 결과를 얻을 수 있습니다.) metric 모델의 성능을 평가할 기준지표 (classification: \"roc_auc\" (default), \"accuracy\" / regression: \"rmse\" (default), \"rsq\") ... hyperparameters의 범위에 대한 Min, Max, Levels 값에 해당하는 파라미터를 지정합니다.","code":""},{"path":"/reference/xgBoost.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"XGBoost — xgBoost","text":"XGBoost","code":""}]
