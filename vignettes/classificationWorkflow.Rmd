---
title: "Classification Modeling Workflow"
output: rmarkdown::html_vignette
vignette: >
  %\VignetteIndexEntry{classificationWorkflow}
  %\VignetteEngine{knitr::rmarkdown}
  %\VignetteEncoding{UTF-8}
---

```{r, include = FALSE}
knitr::opts_chunk$set(
  collapse = TRUE,
  comment = "#>"
)
```

## R environment

```{r setup}
require(dplyr)
library(goophi)
```

#### Camel case : 유저로부터 받는 입력 및 goophi의 함수들
#### Snake case: Shiny app의 server에서 사용(될 것이라고 예상)하는 Object명 및 snake case로 작성된 dependencies의 함수명

## 0. Import sample data

#### 샘플데이터를 불러와 전처리 합니다. (여기까지의 작업은 앞서 이미 진행되었다고 가정)

```{r}
data(titanic_train, package = "titanic")

cleaned_data <- tibble::as_tibble(titanic_train) %>%
  dplyr::select(-c(PassengerId, Name, Cabin, Ticket)) %>%
  dplyr::mutate(across(where(is.character), factor)) %>%
  dplyr::mutate(Survived = as.factor(Survived ))

rec <- recipes::recipe(Survived ~ ., data = cleaned_data) %>%
  recipes::step_dummy(recipes::all_predictors(), -recipes::all_numeric())

rec_prep <- recipes::prep(rec)

cleaned_data <- recipes::bake(rec_prep, new_data = cleaned_data)
knitr::kable(head(cleaned_data, 10))
```

## 1. Train-test split Tab

|    User Input |                                    description |
|--------------:|-----------------------------------------------:|
|     targetVar |                       목적 변수(target, label) |
| trainSetRatio | 전체 데이터 중 train set의 비율 (range: 0 - 1) |

### 1) User input

```{r}
targetVar <- "Survived"
trainSetRatio <- "0.7"
```

### 2) Train-test split 작업이 완료된 Object를 저장하고, Train set을 보여줍니다.

```{r}
split_tmp <- goophi::trainTestSplit(data = cleaned_data, 
                                    target = targetVar, 
                                    prop = trainSetRatio,
                                    seed = 1234)
data_train <- split_tmp[[1]] # train data
data_test <- split_tmp[[2]] # test data
data_split <- split_tmp[[3]] # whole data with split information

DT::datatable(data_train, options = list(scrollX = TRUE))
```

## 2. Preprocessing Tab

### 설명

#### Train set에 대한 전처리 방식을 설정합니다. 예측 변수(features, attributes)는 0번째 단계에서 유저가 원하는 column을 선택했다고 가정하고, 전체를 사용합니다. PCA는 아직 구현되지 않았습니다.

|        User Input |                                             description |
|-------------------:|---------------------------------------------------:|
|        imputation |                          imputation 적용 여부 (Boolean) |
|     normalization |                       normalization 적용 여부 (Boolean) |
|               pca |                                 pca 적용 여부 (Boolean) |
|          pcaThres | 주요 성분 선택 기준이 되는 전체 고유값에 대한 threshold |
|    imputationType |                                         imputation 방식 |
| normalizationType |                                      normalization 방식 |

### 1) User input

```{r}
formula <- paste0(targetVar, " ~ .") # user 입력 x (1에서 user가 targetVar를 입력했을 때 함께 생성) 

imputation <- TRUE
normalization <- TRUE
pca <- FALSE
pcaThres <- "0.7"
imputationType = "mean" 
normalizationType = "range" 
```

### 2) train set에 적용할 전처리 정보를 담은 recipe를 생성합니다

```{r}
rec <- goophi::prepForCV(data = data_train,
                         formula = formula,
                         imputationType = imputationType,
                         normalizationType = normalizationType,
                         pcaThres = pcaThres,
                         imputation = imputation,
                         normalization = normalization,
                         pca = pca,
                         seed = 1234)
```

## 3. Modeling with CV Tab

### 설명

#### grid search, cross validation을 통해 유저가 선택한 모델을 fitting합니다.

| User Input |                                             description |
|-----------:|--------------------------------------------------------:|
|       algo |                                            ML 모델 선택 |
|     engine |                                             engine 선택 |
|       mode |                                               mode 선택 |
|     metric |                   Best performance에 대한 평가지표 선택 |
|          v | Cross validation시 train set을 몇 번 분할할 것인지 입력 |

```{r}
# 모델 object를 저장할 빈 리스트를 생성합니다.
models_list <- list()
```

### 1) logistic

```{r}
## User input

mode <- "classification"
algo <- "LogisticR"
engine <- "glm"

penaltyRangeMin = "0.1"
penaltyRangeMax = "20"
penaltyRangeLevels = "5"
mixtureRangeMin = "0.0"
mixtureRangeMax = "1.0"
mixtureRangeLevels = "5"


v <- "2"

metric <- "roc_auc"

## modeling

if (algo == "LogisticR") {
  
  grid_search_result <- goophi::logisticRegression_phi(engine = engine,
                         mode = mode,
                         data = data_train,
                         rec = rec,
                         v = 2,
                         penaltyRangeMin = penaltyRangeMin,
                         penaltyRangeMax = penaltyRangeMax,
                         penaltyRangeLevels = penaltyRangeLevels,
                         mixtureRangeMin = mixtureRangeMin,
                         mixtureRangeMax = mixtureRangeMax,
                         mixtureRangeLevels = mixtureRangeLevels
                         )

  
  finalized <- goophi::fitBestModel(gridSearchResult = grid_search_result,
                                    metric = metric,
                                    model = model,
                                    formula = formula,
                                    trainingData = data_train,
                                    splitedData = data_split,
                                    algo = paste0(algo,"_",engine))

  models_list <- append(models_list, list(finalized[[2]]))
}
```


### User input

```{r}
# 모델링 과정에서 사용할 engine, mode를 입력받습니다. 
mode <- "classification"
algo <- "randomForest" # 해당 mode에 해당하는 algorithms 보여주기
engine <- "partykit" # 해당 algo에 해당하는 engine 보여주기

# algo, engine에 맞는 hyperparameter를 입력받습니다 (모델마다 상이함, 정리필요). 
minNRangeMin <- "10"
minNRangeMax <- "40"
mtryRangeMin <- "1"
mtryRangeMax <- "5"
treesRangeMin <- "500"
treesRangeMax <- "2000"
levels <- "2"

# training data를 몇 개로 나눌지 입력받습니다.
v <- "2"

# 어떤 지표로 best performance를 평가할건지 입력받습니다(정리필요).
metric <- "roc_auc"
```

### grid search + cross validation + modeling

```{r}

# 사용자정의 ML 모델을 생성합니다
if (algo == "randomForest") {
  
  model <- goophi::randomForest_phi(engine = engine,
                                    mode = mode)

  minNRange <- c(as.numeric(minNRangeMin), as.numeric(minNRangeMax))
  mtryRange <- c(as.numeric(mtryRangeMin), as.numeric(mtryRangeMax))
  treesRange <- c(as.numeric(treesRangeMin), as.numeric(treesRangeMax))
  
  parameterGrid <- dials::grid_regular(
    min_n(range = minNRange),
    mtry(range = mtryRange),
    trees(range = treesRange),
    levels = as.numeric(levels))
  
  # parameter grid를 적용한 cross validation을 수행합니다
  grid_search_result <- goophi::gridSearchCV(rec = rec,
                             model = model,
                             v = v,
                             data = data_train,
                             parameterGrid = parameterGrid,
                             seed = 1234
  )
  
  # 가장 성능이 좋은 모델을 저장합니다
  finalized <- goophi::fitBestModel(gridSearchResult = grid_search_result,
                                    metric = metric,
                                    model = model,
                                    formula = formula,
                                    trainingData = data_train,
                                    splitedData = data_split,
                                    algo = paste0(algo,"_",engine))
  
  models_list[[paste0(algo,"_",engine)]] <- finalized$finalFittedModel
}
```

#### 두 번째 모델을 저장합니다. (Shiny app에서는 + 버튼으로 모델 추가할 수 있도록?)

### User input

```{r}
algo <- "KNN"
engine <- "kknn"
mode <- "classification"

neighborsRangeMin <- "2"
neighborsRangeMax <- "6"
levels <- "1"

v <- "2"

metricIndex <- "roc_auc"
```

### grid search + cross validation + modeling

```{r}
if (algo == "KNN") {
  model <- goophi::knn_phi(engine = engine,
                         mode = mode)

  neighborsRange <- c(as.numeric(neighborsRangeMin), as.numeric(neighborsRangeMax))
  
  parameterGrid <- dials::grid_regular(
    neighbors(range = neighborsRange),
    levels = as.numeric(levels))
  
  grid_search_result <- goophi::gridSearchCV(rec = rec,
                             model = model,
                             v = v,
                             data = data_train,
                             parameterGrid = parameterGrid
  )
  
  finalized <- goophi::fitBestModel(gridSearchResult = grid_search_result,
                                    metric = metricIndex,
                                    model = model,
                                    formula = formula,
                                    trainingData = data_train,
                                    splitedData = data_split,
                                    algo = paste0(algo,"_",engine))

  models_list[[paste0(algo,"_",engine)]] <- finalized$finalFittedModel
}

```

## 4. Report Tab

### 1) ROC Curve

```{r, fig.width = 7, fig.height = 7}
roc_curve <- goophi::rocCurve(modelsList = models_list, 
                 targetVar = targetVar)
roc_curve
```

### 2) Confusion Matrix

### User input

```{r}
model_name = "randomForest_ranger" # 원하는 모델의 이름 입력받기
```

```{r, fig.width = 7, fig.height = 6}
cm <- goophi::confusionMatrix(modelName = model_name,
                              modelsList = models_list,
                              targetVar = targetVar)
cm
```

### 3) Evaluation metrics

```{r}
evalMet <- goophi::evalMetrics(models_list, targetVar)
knitr::kable(evalMet)
```
