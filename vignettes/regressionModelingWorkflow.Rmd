---
title: "Regression Modeling Workflow"
output: rmarkdown::html_vignette
vignette: >
  %\VignetteIndexEntry{regressionModelingWorkflow}
  %\VignetteEngine{knitr::rmarkdown}
  %\VignetteEncoding{UTF-8}
---

```{r, include = FALSE}
knitr::opts_chunk$set(
  collapse = TRUE,
  comment = "#>"
)
```

## R environment

```{r setup}
require(dplyr) # import for loading/preprocessing the sample data
require(MASS)
data("Boston")
attach(Boston)
library(goophi)
```

#### Camel case : 유저로부터 받는 입력 및 goophi의 함수들
#### Snake case: Shiny app의 server에서 사용(될 것이라고 예상)하는 변수명 및 snake case로 작성된 dependencies의 함수명

## 0. Import sample data

#### 샘플데이터를 불러와 전처리 합니다. (여기까지의 작업은 앞서 이미 진행되었다고 가정)

```{r}
cleaned_data <- Boston %>%
  mutate(chas = as.factor(chas))

knitr::kable(head(cleaned_data, 10))
```
## 1. Train-test split Tab

#### train set, test set을 분리합니다.

|    User Input |                                    description |
|--------------:|-----------------------------------------------:|
|     targetVar |                       목적 변수(target, label) |
| trainSetRatio | 전체 데이터 중 train set의 비율 (range: 0 - 1) |

### User input

```{r}
targetVar <- "crim"
trainSetRatio <- "0.7"
```

### Train-test split 작업이 완료된 Object를 저장하고, Train set을 보여줍니다.

```{r}
split_tmp <- goophi::trainTestSplit(data = cleaned_data, target = targetVar, prop = trainSetRatio)
data_train <- split_tmp$train # train data
data_test <- split_tmp$test # test data
data_split <- split_tmp$dataSplit # whole data with split information

DT::datatable(data_train, options = list(scrollX = TRUE))
```

## 2. Preprocessing Tab

#### Train set에 대한 전처리 방식을 설정합니다. 예측 변수(features, attributes)는 0번째 단계에서 유저가 원하는 column을 선택했다고 가정하고, 전체를 사용합니다. PCA는 아직 구현되지 않았습니다.

|        User Input |                                             description |
|-------------------:|---------------------------------------------------:|
|        imputation |                          imputation 적용 여부 (Boolean) |
|     normalization |                       normalization 적용 여부 (Boolean) |
|               pca |                                 pca 적용 여부 (Boolean) |
|          pcaThres | 주요 성분 선택 기준이 되는 전체 고유값에 대한 threshold |
|    imputationType |                                         imputation 방식 |
| normalizationType |                                      normalization 방식 |

### User input

```{r}
formula <- paste0(targetVar, " ~ .") # user 입력 x (1에서 user가 targetVar를 입력했을 때 함께 생성) 

imputation <- TRUE
normalization <- TRUE
imputationType = "mean" 
normalizationType = "range" 
```

### train set에 적용할 전처리 정보를 담은 recipe를 생성합니다

```{r}
rec <- goophi::prepForCV(data = data_train,
                         formula = formula,
                         imputationType = imputationType,
                         normalizationType = normalizationType,
                         imputation = imputation,
                         normalization = normalization,
                         seed = 1234)
```

## 3. Modeling with CV Tab

#### grid search, cross validation을 통해 유저가 선택한 모델을 fitting합니다.

| User Input |                                             description |
|-----------:|--------------------------------------------------------:|
|       algo |                                            ML 모델 선택 |
|     engine |                                             engine 선택 |
|       mode |                                               mode 선택 |
|     metric |                   Best performance에 대한 평가지표 선택 |
|          v | Cross validation시 train set을 몇 번 분할할 것인지 입력 |

```{r}
# 모델 object를 저장할 빈 리스트를 생성합니다.
models_list <- list()
```


### 1) linear regression model

```{r}
## User input

mode <- "regression"
algo <- "LinearR"
engine <- "glmnet"

penaltyRangeMin = "0.1"
penaltyRangeMax = "20"
penaltyRangeLevels = "5"
mixtureRangeMin = "0.0"
mixtureRangeMax = "1.0"
mixtureRangeLevels = "5"

v <- "2"

metric <- "rmse"

## grid search + cross validation + modeling

finalized <- goophi::linearRegression(algo = algo,
                                      engine = engine,
                                      mode = mode,
                                      trainingData = data_train,
                                      splitedData = data_split,
                                      formula = formula,
                                      rec = rec,
                                      v = 2,
                                      penaltyRangeMin = penaltyRangeMin,
                                      penaltyRangeMax = penaltyRangeMax,
                                      penaltyRangeLevels = penaltyRangeLevels,
                                      mixtureRangeMin = mixtureRangeMin,
                                      mixtureRangeMax = mixtureRangeMax,
                                      mixtureRangeLevels = mixtureRangeLevels,
                                      metric = metric
                                      )

## models_list에 모델을 추가합니다.
models_list[[paste0(algo,"_",engine)]] <- finalized$finalFittedModel
```


### 2) K Nearest Neighbor

```{r}
## User input

mode <- "regression"
algo <- "KNN"
engine <- "kknn"

neighborsRangeMin = "2"
neighborsRangeMax = "8"
neighborsRangeLevels = "4"

v <- "2"

metric <- "rmse"

## grid search + cross validation + modeling

finalized <- goophi::KNN(algo = algo,
                         engine = engine,
                         mode = mode,
                         trainingData = data_train,
                         splitedData = data_split,
                         formula = formula,
                         rec = rec,
                         v = 2,
                         neighborsRangeMin = neighborsRangeMin,
                         neighborsRangeMax = neighborsRangeMax,
                         neighborsRangeLevels = neighborsRangeLevels,
                         metric = metric
                         )

## models_list에 모델을 추가합니다.
models_list[[paste0(algo,"_",engine)]] <- finalized$finalFittedModel
```

### 3) MLP

```{r}
## User input

mode <- "regression"
algo <- "MLP"
engine <- "nnet"

hiddenUnitsRangeMin = "1"
hiddenUnitsRangeMax = "10"
hiddenUnitsRangeLevels = "3"
penaltyRangeMin = "0.01"
penaltyRangeMax = "0.5"
penaltyRangeLevels = "3"
dropoutRangeMin = "0"
dropoutRangeMax = "1"
dropoutRangeLevels = "2"
epochsRangeMin = "10"
epochsRangeMax = "100"
epochsRangeLevels = "2"
activation = "linear" #"linear", "softmax", "relu", "elu"
learnRateRangeMin = "0"
learnRateRangeMax = "1"
learnRateRangeLevels = "2"


v <- "2"

metric <- "rmse"

## grid search + cross validation + modeling

finalized <- goophi::MLP(algo = algo,
                         engine = engine,
                         mode = mode,
                         trainingData = data_train,
                         splitedData = data_split,
                         formula = formula,
                         rec = rec,
                         v = 2,
                         hiddenUnitsRangeMin = hiddenUnitsRangeMin,
                         hiddenUnitsRangeMax = hiddenUnitsRangeMax,
                         hiddenUnitsRangeLevels = hiddenUnitsRangeLevels,
                         penaltyRangeMin = penaltyRangeMin,
                         penaltyRangeMax = penaltyRangeMax,
                         penaltyRangeLevels = penaltyRangeLevels,
                         dropoutRangeMin = dropoutRangeMin,
                         dropoutRangeMax = dropoutRangeMax,
                         dropoutRangeLevels = dropoutRangeLevels,
                         epochsRangeMin = epochsRangeMin,
                         epochsRangeMax = epochsRangeMax,
                         epochsRangeLevels = epochsRangeLevels,
                         activation = activation, #"linear", "softmax", "relu", "elu"
                         learnRateRangeMin = learnRateRangeMin,
                         learnRateRangeMax = learnRateRangeMax,
                         learnRateRangeLevels = learnRateRangeLevels,
                         metric = metric
                         )

## models_list에 모델을 추가합니다.
models_list[[paste0(algo,"_",engine)]] <- finalized$finalFittedModel
```

### 4) Decision Tree

```{r}
## User input

mode <- "regression"
algo <- "Decision Tree"
engine <- "rpart"

treeDepthRangeMin = "3"
treeDepthRangeMax = "10"
treeDepthRangeLevels = "3"
minNRangeMin = "10"
minNRangeMax = "50"
minNRangeLevels = "3"
costComplexityRangeMin = "-1"
costComplexityRangeMax = "5"
costComplexityRangeLevels = "3"

v <- "2"

metric <- "rmse"

## grid search + cross validation + modeling

finalized <- goophi::decisionTree(algo = algo,
                                  engine = engine,
                                  mode = mode,
                                  trainingData = data_train,
                                  splitedData = data_split,
                                  formula = formula,
                                  rec = rec,
                                  v = 2,
                                  treeDepthRangeMin = treeDepthRangeMin,
                                  treeDepthRangeMax = treeDepthRangeMax,
                                  treeDepthRangeLevels = treeDepthRangeLevels,
                                  minNRangeMin = minNRangeMin,
                                  minNRangeMax = minNRangeMax,
                                  minNRangeLevels = minNRangeLevels,
                                  costComplexityRangeMin = costComplexityRangeMin,
                                  costComplexityRangeMax = costComplexityRangeMax,
                                  costComplexityRangeLevels = costComplexityRangeLevels,
                                  metric = metric
                                  )

## models_list에 모델을 추가합니다.
models_list[[paste0(algo,"_",engine)]] <- finalized$finalFittedModel

## A correlation computation is required, but `estimate` is constant and has 0 standard deviation ... warning은 
```
### 5) Random Forest

```{r}
## User input

mode <- "regression"
algo <- "Random Forest"
engine <- "ranger"

mtryRangeMin <- "1"
mtryRangeMax <- "5"
mtryRangeLevels <- "3"
treesRangeMin <- "500"
treesRangeMax <- "2000"
treesRangeLevels <- "3"
minNRangeMin <- "1"
minNRangeMax <- "10"
minNRangeLevels <- "3"

v <- "2"

metric <- "rmse"

## grid search + cross validation + modeling

finalized <- goophi::randomForest(algo = algo,
                                  engine = engine,
                                  mode = mode,
                                  trainingData = data_train,
                                  splitedData = data_split,
                                  formula = formula,
                                  rec = rec,
                                  v = 2,
                                  mtryRangeMin = mtryRangeMin,
                                  mtryRangeMax = mtryRangeMax,
                                  mtryRangeLevels = mtryRangeLevels,
                                  treesRangeMin = treesRangeMin,
                                  treesRangeMax = treesRangeMax,
                                  treesRangeLevels = treesRangeLevels,
                                  minNRangeMin = minNRangeMin,
                                  minNRangeMax = minNRangeMax,
                                  minNRangeLevels = minNRangeLevels,
                                  metric = metric
                                  )

## models_list에 모델을 추가합니다.
models_list[[paste0(algo,"_",engine)]] <- finalized$finalFittedModel
```

### 6) XGBoost

```{r}
## User input

mode <- "regression"
algo <- "XGBoost"
engine <- "xgboost"

treeDepthRangeMin <- "3"
treeDepthRangeMax <- "6"
treeDepthRangeLevels <- "2"
treesRangeMin <- "10"
treesRangeMax <- "15"
treesRangeLevels <- "2"
learnRateRangeMin <- "0.01"
learnRateRangeMax <- "0.3"
learnRateRangeLevels <- "2"
mtryRangeMin <- "1"
mtryRangeMax <- "9"
mtryRangeLevels <- "3"
minNRangeMin <- "1"
minNRangeMax <- "10"
minNRangeLevels <- "3"
lossReductionRangeMin <- "0"
lossReductionRangeMax <- "10"
lossReductionRangeLevels <- "2"
sampleSizeRangeMin <- "0"
sampleSizeRangeMax <- "1"
sampleSizeRangeLevels <- "2"
stopIter <- "10"

v <- "2"

metric <- "rmse"

## grid search + cross validation + modeling

finalized <- goophi::xgboost(algo = algo,
                                  engine = engine,
                                  mode = mode,
                                  trainingData = data_train,
                                  splitedData = data_split,
                                  formula = formula,
                                  rec = rec,
                                  v = 2,
                                  treeDepthRangeMin = treeDepthRangeMin,
                                  treeDepthRangeMax = treeDepthRangeMax,
                                  treeDepthRangeLevels = treeDepthRangeLevels,
                                  treesRangeMin = treesRangeMin,
                                  treesRangeMax = treesRangeMax,
                                  treesRangeLevels = treesRangeLevels,
                                  learnRateRangeMin = learnRateRangeMin,
                                  learnRateRangeMax = learnRateRangeMax,
                                  learnRateRangeLevels = learnRateRangeLevels,
                                  mtryRangeMin = mtryRangeMin,
                                  mtryRangeMax = mtryRangeMax,
                                  mtryRangeLevels = mtryRangeLevels,
                                  minNRangeMin = minNRangeMin,
                                  minNRangeMax = minNRangeMax,
                                  minNRangeLevels = minNRangeLevels,
                                  lossReductionRangeMin = lossReductionRangeMin,
                                  lossReductionRangeMax = lossReductionRangeMax,
                                  lossReductionRangeLevels = lossReductionRangeLevels,
                                  sampleSizeRangeMin = sampleSizeRangeMin,
                                  sampleSizeRangeMax = sampleSizeRangeMax,
                                  sampleSizeRangeLevels = sampleSizeRangeLevels,
                                  stopIter = stopIter,
                                  metric = metric
                                  )

## models_list에 모델을 추가합니다.
models_list[[paste0(algo,"_",engine)]] <- finalized$finalFittedModel
```


### 7) lightGBM

```{r}
## User input

mode <- "regression"
algo <- "light GBM"
engine <- "lightgbm"

treeDepthRangeMin <- "3"
treeDepthRangeMax <- "6"
treeDepthRangeLevels <- "2"
treesRangeMin <- "10"
treesRangeMax <- "15"
treesRangeLevels <- "2"
learnRateRangeMin <- "0.01"
learnRateRangeMax <- "0.3"
learnRateRangeLevels <- "2"
mtryRangeMin <- "1"
mtryRangeMax <- "9"
mtryRangeLevels <- "3"
minNRangeMin <- "1"
minNRangeMax <- "10"
minNRangeLevels <- "3"
lossReductionRangeMin <- "0"
lossReductionRangeMax <- "10"
lossReductionRangeLevels <- "2"

v <- "2"

metric <- "rmse"

## grid search + cross validation + modeling

finalized <- goophi::lightGbm(algo = algo,
                                  engine = engine,
                                  mode = mode,
                                  trainingData = data_train,
                                  splitedData = data_split,
                                  formula = formula,
                                  rec = rec,
                                  v = 2,
                                  treeDepthRangeMin = treeDepthRangeMin,
                                  treeDepthRangeMax = treeDepthRangeMax,
                                  treeDepthRangeLevels = treeDepthRangeLevels,
                                  treesRangeMin = treesRangeMin,
                                  treesRangeMax = treesRangeMax,
                                  treesRangeLevels = treesRangeLevels,
                                  learnRateRangeMin = learnRateRangeMin,
                                  learnRateRangeMax = learnRateRangeMax,
                                  learnRateRangeLevels = learnRateRangeLevels,
                                  mtryRangeMin = mtryRangeMin,
                                  mtryRangeMax = mtryRangeMax,
                                  mtryRangeLevels = mtryRangeLevels,
                                  minNRangeMin = minNRangeMin,
                                  minNRangeMax = minNRangeMax,
                                  minNRangeLevels = minNRangeLevels,
                                  lossReductionRangeMin = lossReductionRangeMin,
                                  lossReductionRangeMax = lossReductionRangeMax,
                                  lossReductionRangeLevels = lossReductionRangeLevels,
                                  metric = metric
                                  )

## models_list에 모델을 추가합니다.
models_list[[paste0(algo,"_",engine)]] <- finalized$finalFittedModel
```


## 4. Report Tab

```{r}
## user input
for (i in 1:7){
  print(models_list[[i]]$.predictions[[1]]$model[1])
}

modelName <- "Random Forest_ranger"
```
### 1) Regression plot

```{r}
models_list[[modelName]] %>% 
  tune::collect_predictions() %>%
  ggplot2::ggplot(aes(x = eval(parse(text = targetVar)), y = models_list[[modelName]]$.predictions[[1]][1]$.pred)) +
  ggplot2::labs(title = "Regression Plot (Truth vs Prediced)",
         x = "Truth",
         y = "Predicted") +
  ggplot2::geom_abline(color = "gray50", lty = 2) + 
  ggplot2::geom_point(alpha = 0.5) + 
  tune::coord_obs_pred()
```
### 2) Evaluation metrics

```{r}
## evaluation index
evalMet <- goophi::evalMetricsR(models_list, targetVar)
knitr::kable(evalMet)
```
