% Generated by roxygen2: do not edit by hand
% Please edit documentation in R/algorithms.R, R/fitting.R, R/report.R
\name{\%>\%}
\alias{\%>\%}
\alias{logisticRegression_phi}
\alias{linearRegression_phi}
\alias{randomForest_phi}
\alias{knn_phi}
\alias{mlp_phi}
\alias{decisionTree_phi}
\alias{naiveBayes_phi}
\alias{xgboost_phi}
\alias{lightGbm_phi}
\alias{kMeansClustering_phi}
\alias{gridSearchCV}
\alias{fitBestModel}
\alias{rocCurve}
\alias{confusionMatrix}
\alias{evalMetrics}
\title{Logistic Regression}
\usage{
logisticRegression_phi(engine = "glm", mode = "classification")

linearRegression_phi(engine = "lm", mode = "regression")

randomForest_phi(engine = "randomForest", mode = "classification")

knn_phi(engine = "kknn", mode = "classification")

mlp_phi(engine = "nnet", mode = "classification")

decisionTree_phi(engine = "rpart", mode = "classification")

naiveBayes_phi(engine = "klaR", mode = "classification")

xgboost_phi(engine = "xgboost", mode = "classification")

lightGbm_phi(engine = "lightgbm", mode = "classification")

kMeansClustering_phi(
  data,
  maxK = 10,
  nstart = 25,
  selectOptimal = "silhouette",
  seed_num = 6471
)

gridSearchCV(rec, model, v = "5", data, parameterGrid, seed = 4814)

fitBestModel(
  gridSearchResult,
  metric,
  model,
  formula,
  trainingData,
  splitedData,
  algo
)

rocCurve(modelsList, targetVar)

confusionMatrix(modelName, modelsList, targetVar)

evalMetrics(modelsList, targetVar)
}
\arguments{
\item{engine}{engine}

\item{mode}{mode}

\item{data}{data}

\item{maxK}{maxK}

\item{nstart}{nstart}

\item{selectOptimal}{selectOptimal}

\item{seed_num}{seed_num}

\item{rec}{rec}

\item{model}{model}

\item{v}{v-fold CV}

\item{seed}{seed}

\item{gridSearchResult}{gridSearchResult}

\item{metric}{metric}

\item{formula}{formula}

\item{trainingData}{trainingData}

\item{splitedData}{splitedData}

\item{algo}{algo}

\item{modelsList}{modelsList}

\item{targetVar}{targetVar}

\item{modelName}{modelName}

\item{parameter_grid}{parameter_grid}

\item{models_list}{models_list}
}
\description{
Logistic Regression

Linear Regression

Random Forest

K-Nearest Neighbors

neural network

Decision Tree

Naive Bayes

XGBoost

Light GBM

K means clustering

Grid Search with cross validation

fitting in best model

AUC-ROC Curve

Confusion matrix

Evaluation metrics
}
\details{
로지스틱 회귀 알고리즘 함수. 예측 변수들이 정규분포를 따르지 않아도 사용할 수 있습니다.
그러나 이 알고리즘은 결과 변수가 선형적으로 구분되며, 예측 변수들의 값이 결과 변수와 선형 관계를
가진다고 가정합니다. 만약 데이터가 이 가정을 충족하지 않는 경우 성능이 저하될 수 있습니다.
hyperparameters: penalty, mixture

Linear Regression
hyperparameters: penalty, mixture

랜덤 포레스트 알고리즘 함수. 여러개의 Decision Tree를 형성.
새로운 데이터 포인트를 각 트리에 동시에 통과 시켜 각 트리가 분류한 결과에서 투표를 실시하여
가장 많이 득표한 결과를 최종 분류 결과로 선택
hyperparameters: trees, min_n, mtry

KNN 알고리즘 함수.
데이터로부터 거리가 가까운 K개의 다른 데이터의 레이블을 참조하여 분류하는 알고리즘
hyperparameters: neighbors

neural network 알고리즘 함수.
neural network 모델은 생물학적인 뉴런을 수학적으로 모델링한 것.
여러개의 뉴런으로부터 입력값을 받아서 세포체에 저장하다가 자신의 용량을 넘어서면 외부로 출력값을 내보내는 것처럼,
인공신경망 뉴런은 여러 입력값을 받아서 일정 수준이 넘어서면 활성화되어 출력값을 내보낸다.
hyperparameters: hidden_units, penalty, dropout, epochs, activation, learn_rate

의사결정나무 알고리즘 함수. 의사 결정 규칙 (Decision rule)을 나무 형태로 분류해 나가는 분석 기법을 말합니다.
hyperparameters: cost_complexity, tree_depth, min_n

Naive Bayes
hyperparameters: smoothness, Laplace

XGBoost
hyperparameters: mtry, min_n, tree_depth, loss_reduction, learn_rate, sample_size

Light GBM
install treesnip package by: remotes::install_github("curso-r/treesnip")
hyperparameters: mtry, min_n, tree_depth, loss_reduction, learn_rate, sample_size

K means clustering
selectOptimal: silhouette, gap_stat
hyperparameters: maxK, nstart

Grid Search with cross validation

fitting in best model

AUC-ROC Curve

Confusion matrix

Evaluation metrics
}
